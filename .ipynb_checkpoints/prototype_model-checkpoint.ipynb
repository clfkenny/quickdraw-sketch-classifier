{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T00:09:49.770612Z",
     "start_time": "2018-07-26T00:09:49.766780Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from sgdr import SGDRScheduler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T00:10:31.622072Z",
     "start_time": "2018-07-26T00:09:50.099127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1335000 images belonging to 89 classes.\n",
      "Found 222500 images belonging to 89 classes.\n",
      "Data batch shape:  (20, 28, 28, 1)\n",
      "Labels batch shape:  (20, 89)\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_dir = \"./train\"\n",
    "validation_dir = \"./test\"\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, \n",
    "    target_size = (28,28),\n",
    "    batch_size=20,\n",
    "    class_mode= 'categorical',\n",
    "    color_mode = 'grayscale')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size = (28,28),\n",
    "    batch_size=20,\n",
    "    class_mode = 'categorical',\n",
    "    color_mode = 'grayscale')\n",
    "\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('Data batch shape: ', data_batch.shape)\n",
    "    print('Labels batch shape: ', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T01:20:03.507729Z",
     "start_time": "2018-07-26T01:20:03.502964Z"
    }
   },
   "outputs": [],
   "source": [
    "# callbacks\n",
    "epochs = 10000\n",
    "batch_size = 64\n",
    "epoch_size = 15000\n",
    "\n",
    "schedule = SGDRScheduler(min_lr=1e-5,\n",
    "                         max_lr=1e-3,\n",
    "                         steps_per_epoch=np.ceil(epoch_size/batch_size),\n",
    "                         lr_decay=0.9,\n",
    "                         cycle_length=10,\n",
    "                         mult_factor=1.5)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./graph', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "filepath=\"models/checkpoints/best_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-25T23:59:55.858387Z",
     "start_time": "2018-07-25T23:59:55.744363Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clearing old graphs...\n"
     ]
    }
   ],
   "source": [
    "# construct model\n",
    "\n",
    "print('\\nClearing old graphs...')\n",
    "graph = os.listdir('graph')\n",
    "for file in graph:\n",
    "  os.remove('graph/{}'.format(file))\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (2,2), activation = 'relu', input_shape = (28, 28, 1)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(64, (2,2), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(128, (2,2), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(89, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T00:02:05.529466Z",
     "start_time": "2018-07-25T23:59:58.550386Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3766"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.4863 - acc: 0.0185 - val_loss: 4.4560 - val_acc: 0.0270\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.61800\n",
      "Epoch 2/10000\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 4.3150 - acc: 0.0415 - val_loss: 4.1001 - val_acc: 0.0580\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.61800\n",
      "Epoch 3/10000\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 3.8806 - acc: 0.0955 - val_loss: 3.6984 - val_acc: 0.1220\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.61800\n",
      "Epoch 4/10000\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 3.6510 - acc: 0.1410 - val_loss: 3.4565 - val_acc: 0.1950\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.61800\n",
      "Epoch 5/10000\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 3.4711 - acc: 0.1645 - val_loss: 3.2867 - val_acc: 0.2160\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.61800\n",
      "Epoch 6/10000\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 3.3154 - acc: 0.1910 - val_loss: 3.1337 - val_acc: 0.2430\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.61800\n",
      "Epoch 7/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 3.2151 - acc: 0.2175 - val_loss: 3.0193 - val_acc: 0.2870\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.61800\n",
      "Epoch 8/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 3.1151 - acc: 0.2360 - val_loss: 2.9474 - val_acc: 0.2960\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.61800\n",
      "Epoch 9/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 3.0240 - acc: 0.2480 - val_loss: 2.8217 - val_acc: 0.3280\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.61800\n",
      "Epoch 10/10000\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 2.9539 - acc: 0.2845 - val_loss: 2.6846 - val_acc: 0.3480\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.61800\n",
      "Epoch 11/10000\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 2.8773 - acc: 0.2940 - val_loss: 2.5887 - val_acc: 0.3760\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.61800\n",
      "Epoch 12/10000\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 2.8801 - acc: 0.2745 - val_loss: 2.5740 - val_acc: 0.3710\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.61800\n",
      "Epoch 13/10000\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 2.7702 - acc: 0.3110 - val_loss: 2.4892 - val_acc: 0.3830\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.61800\n",
      "Epoch 14/10000\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 2.6288 - acc: 0.3385 - val_loss: 2.4254 - val_acc: 0.4110\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.61800\n",
      "Epoch 15/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 2.6270 - acc: 0.3480 - val_loss: 2.4507 - val_acc: 0.3960\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.61800\n",
      "Epoch 16/10000\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 2.6404 - acc: 0.3480 - val_loss: 2.4286 - val_acc: 0.4090\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.61800\n",
      "Epoch 17/10000\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 2.5727 - acc: 0.3590 - val_loss: 2.3223 - val_acc: 0.4410\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.61800\n",
      "Epoch 18/10000\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 2.4691 - acc: 0.3650 - val_loss: 2.2701 - val_acc: 0.4500\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.61800\n",
      "Epoch 19/10000\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 2.4853 - acc: 0.3750 - val_loss: 2.2422 - val_acc: 0.4570\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.61800\n",
      "Epoch 20/10000\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 2.4718 - acc: 0.3680 - val_loss: 2.2015 - val_acc: 0.4550\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.61800\n",
      "Epoch 21/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 2.4070 - acc: 0.4070 - val_loss: 2.1566 - val_acc: 0.4640\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.61800\n",
      "Epoch 22/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 2.4543 - acc: 0.3865 - val_loss: 2.1696 - val_acc: 0.4660\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.61800\n",
      "Epoch 23/10000\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 2.3929 - acc: 0.3900 - val_loss: 2.1405 - val_acc: 0.4600\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.61800\n",
      "Epoch 24/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 2.3539 - acc: 0.3915 - val_loss: 2.1106 - val_acc: 0.4660\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.61800\n",
      "Epoch 25/10000\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 2.3355 - acc: 0.4080 - val_loss: 2.1025 - val_acc: 0.4740\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.61800\n",
      "Epoch 26/10000\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 2.2943 - acc: 0.4255 - val_loss: 2.0669 - val_acc: 0.4860\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.61800\n",
      "Epoch 27/10000\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 2.3611 - acc: 0.4140 - val_loss: 2.0505 - val_acc: 0.4920\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.61800\n",
      "Epoch 28/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.1931 - acc: 0.4345 - val_loss: 2.0056 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.61800\n",
      "Epoch 29/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.2980 - acc: 0.4350 - val_loss: 2.0123 - val_acc: 0.4850\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.61800\n",
      "Epoch 30/10000\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 2.2788 - acc: 0.4270 - val_loss: 1.9745 - val_acc: 0.5010\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.61800\n",
      "Epoch 31/10000\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 2.2965 - acc: 0.4340 - val_loss: 1.9804 - val_acc: 0.5050\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.61800\n",
      "Epoch 32/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.1914 - acc: 0.4325 - val_loss: 1.9248 - val_acc: 0.5080\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.61800\n",
      "Epoch 33/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 2.1554 - acc: 0.4470 - val_loss: 1.9202 - val_acc: 0.5260\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.61800\n",
      "Epoch 34/10000\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 2.0757 - acc: 0.4485 - val_loss: 1.9766 - val_acc: 0.4990\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.61800\n",
      "Epoch 35/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.1277 - acc: 0.4575 - val_loss: 1.9176 - val_acc: 0.5070\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.61800\n",
      "Epoch 36/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.1824 - acc: 0.4545 - val_loss: 1.8884 - val_acc: 0.5190\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.61800\n",
      "Epoch 37/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.1508 - acc: 0.4430 - val_loss: 1.8907 - val_acc: 0.5160\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.61800\n",
      "Epoch 38/10000\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 2.1244 - acc: 0.4740 - val_loss: 1.8421 - val_acc: 0.5360\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.61800\n",
      "Epoch 39/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.1197 - acc: 0.4705 - val_loss: 1.8329 - val_acc: 0.5490\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.61800\n",
      "Epoch 40/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.1466 - acc: 0.4645 - val_loss: 1.8767 - val_acc: 0.5220\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.61800\n",
      "Epoch 41/10000\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 2.0304 - acc: 0.4840 - val_loss: 1.8290 - val_acc: 0.5410\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.61800\n",
      "Epoch 42/10000\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 2.1543 - acc: 0.4610 - val_loss: 1.8017 - val_acc: 0.5480\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.61800\n",
      "Epoch 43/10000\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 2.0850 - acc: 0.4670 - val_loss: 1.8302 - val_acc: 0.5310\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.61800\n",
      "Epoch 44/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.1516 - acc: 0.4750 - val_loss: 1.8199 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00044: val_acc did not improve from 0.61800\n",
      "Epoch 45/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.0760 - acc: 0.4805 - val_loss: 1.7825 - val_acc: 0.5510\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.61800\n",
      "Epoch 46/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.1003 - acc: 0.4795 - val_loss: 1.7726 - val_acc: 0.5550\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.61800\n",
      "Epoch 47/10000\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 2.0971 - acc: 0.4675 - val_loss: 1.7436 - val_acc: 0.5640\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.61800\n",
      "Epoch 48/10000\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 2.0107 - acc: 0.4935 - val_loss: 1.7224 - val_acc: 0.5610\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.61800\n",
      "Epoch 49/10000\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 2.0351 - acc: 0.4740 - val_loss: 1.7263 - val_acc: 0.5480\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.61800\n",
      "Epoch 50/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 1.9669 - acc: 0.4985 - val_loss: 1.7298 - val_acc: 0.5590\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.61800\n",
      "Epoch 51/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 2.0035 - acc: 0.4905 - val_loss: 1.7353 - val_acc: 0.5620\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.61800\n",
      "Epoch 52/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.9561 - acc: 0.5015 - val_loss: 1.6981 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.61800\n",
      "Epoch 53/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.9903 - acc: 0.4990 - val_loss: 1.7097 - val_acc: 0.5530\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.61800\n",
      "Epoch 54/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 1.9524 - acc: 0.4970 - val_loss: 1.6934 - val_acc: 0.5670\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.61800\n",
      "Epoch 55/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.0073 - acc: 0.4880 - val_loss: 1.6718 - val_acc: 0.5750\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.61800\n",
      "Epoch 56/10000\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 1.9142 - acc: 0.5120 - val_loss: 1.6486 - val_acc: 0.5810\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.61800\n",
      "Epoch 57/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 1.9031 - acc: 0.5105 - val_loss: 1.6621 - val_acc: 0.5720\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.61800\n",
      "Epoch 58/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.9283 - acc: 0.5080 - val_loss: 1.6382 - val_acc: 0.5810\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.61800\n",
      "Epoch 59/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.9565 - acc: 0.5005 - val_loss: 1.6651 - val_acc: 0.5680\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.61800\n",
      "Epoch 60/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.9123 - acc: 0.5120 - val_loss: 1.6357 - val_acc: 0.5830\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.61800\n",
      "Epoch 61/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.9972 - acc: 0.4960 - val_loss: 1.6737 - val_acc: 0.5760\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.61800\n",
      "Epoch 62/10000\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 1.9845 - acc: 0.4900 - val_loss: 1.6325 - val_acc: 0.5890\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.61800\n",
      "Epoch 63/10000\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 1.8848 - acc: 0.5240 - val_loss: 1.6367 - val_acc: 0.5840\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.61800\n",
      "Epoch 64/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 1.9588 - acc: 0.4985 - val_loss: 1.5965 - val_acc: 0.6020\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.61800\n",
      "Epoch 65/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.8787 - acc: 0.5380 - val_loss: 1.6396 - val_acc: 0.5980\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.61800\n",
      "Epoch 66/10000\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 1.9039 - acc: 0.5195 - val_loss: 1.6039 - val_acc: 0.5830\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.61800\n",
      "Epoch 67/10000\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 1.8341 - acc: 0.5185 - val_loss: 1.6359 - val_acc: 0.5830\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.61800\n",
      "Epoch 68/10000\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 1.8438 - acc: 0.5270 - val_loss: 1.6186 - val_acc: 0.5940\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.61800\n",
      "Epoch 69/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.8758 - acc: 0.5160 - val_loss: 1.5740 - val_acc: 0.6020\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.61800\n",
      "Epoch 70/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.8622 - acc: 0.5260 - val_loss: 1.5662 - val_acc: 0.5850\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.61800\n",
      "Epoch 71/10000\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 1.8688 - acc: 0.5090 - val_loss: 1.5771 - val_acc: 0.5820\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.61800\n",
      "Epoch 72/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.8564 - acc: 0.5180 - val_loss: 1.6019 - val_acc: 0.5990\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.61800\n",
      "Epoch 73/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.8691 - acc: 0.5340 - val_loss: 1.5884 - val_acc: 0.6010\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.61800\n",
      "Epoch 74/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.8437 - acc: 0.5325 - val_loss: 1.5602 - val_acc: 0.6040\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.61800\n",
      "Epoch 75/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.8484 - acc: 0.5320 - val_loss: 1.5629 - val_acc: 0.6060\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.61800\n",
      "Epoch 76/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.8647 - acc: 0.5300 - val_loss: 1.5409 - val_acc: 0.6120\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.61800\n",
      "Epoch 77/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.7821 - acc: 0.5435 - val_loss: 1.5362 - val_acc: 0.5930\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.61800\n",
      "Epoch 78/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.8255 - acc: 0.5400 - val_loss: 1.5707 - val_acc: 0.6090\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.61800\n",
      "Epoch 79/10000\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 1.8366 - acc: 0.5305 - val_loss: 1.5163 - val_acc: 0.6130\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.61800\n",
      "Epoch 80/10000\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 1.8191 - acc: 0.5360 - val_loss: 1.5463 - val_acc: 0.6130\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.61800\n",
      "Epoch 81/10000\n",
      " 70/100 [====================>.........] - ETA: 0s - loss: 1.8310 - acc: 0.5400"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-185be0c8aa0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     callbacks = [schedule, tensorboard, checkpoint])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"models/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "hist = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 100,\n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps=50,\n",
    "    callbacks = [schedule, tensorboard, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T01:19:30.715630Z",
     "start_time": "2018-07-26T01:19:30.304830Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "json_file = open('models/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights('models/checkpoints/best_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T00:59:43.433182Z",
     "start_time": "2018-07-26T00:59:43.430580Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "categories = os.listdir('full')\n",
    "categories = [s.replace('.npy', '') for s in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T01:21:27.516904Z",
     "start_time": "2018-07-26T01:21:27.398825Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenny/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f70eff105c0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import imageio\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "test_pred = imageio.imread('test_predictions/my_own_drawings/my_lightning.png', pilmode = 'L')\n",
    "test_pred = np.invert(test_pred)\n",
    "test_pred = imresize(test_pred, (28,28) )\n",
    "\n",
    "# test_pred = imageio.imread('test_predictions/lightning0.png')\n",
    "\n",
    "plt.imshow(test_pred/255, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T01:21:29.732886Z",
     "start_time": "2018-07-26T01:21:29.694856Z"
    }
   },
   "outputs": [],
   "source": [
    "test_pred_reshaped = test_pred.reshape(1, 28, 28, 1)/255\n",
    "pred = loaded_model.predict(test_pred_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T01:21:30.068349Z",
     "start_time": "2018-07-26T01:21:30.031070Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classes</th>\n",
       "      <th>probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>zigzag</td>\n",
       "      <td>0.168252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>lightning</td>\n",
       "      <td>0.133673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>squiggle</td>\n",
       "      <td>0.101783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>rainbow</td>\n",
       "      <td>0.044992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>hammer</td>\n",
       "      <td>0.041519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>rifle</td>\n",
       "      <td>0.035278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>pliers</td>\n",
       "      <td>0.029695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>flip_flops</td>\n",
       "      <td>0.029138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aircraft_carrier</td>\n",
       "      <td>0.022976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>crocodile</td>\n",
       "      <td>0.020514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airplane</td>\n",
       "      <td>0.017754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>pencil</td>\n",
       "      <td>0.014396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bandage</td>\n",
       "      <td>0.014020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>brain</td>\n",
       "      <td>0.013617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>boomerang</td>\n",
       "      <td>0.013593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>helicopter</td>\n",
       "      <td>0.013583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>carrot</td>\n",
       "      <td>0.012211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>saw</td>\n",
       "      <td>0.010504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arm</td>\n",
       "      <td>0.009910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>dolphin</td>\n",
       "      <td>0.009853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>guitar</td>\n",
       "      <td>0.009802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>hamburger</td>\n",
       "      <td>0.009717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.009479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>binoculars</td>\n",
       "      <td>0.009270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bird</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>rabbit</td>\n",
       "      <td>0.008420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>baseball</td>\n",
       "      <td>0.008132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>sword</td>\n",
       "      <td>0.008027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>belt</td>\n",
       "      <td>0.007731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bench</td>\n",
       "      <td>0.007535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>light_bulb</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>triangle</td>\n",
       "      <td>0.002302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bathtub</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>basketball</td>\n",
       "      <td>0.001986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>mountain</td>\n",
       "      <td>0.001929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>cat</td>\n",
       "      <td>0.001878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>skull</td>\n",
       "      <td>0.001703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>sheep</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>cow</td>\n",
       "      <td>0.001669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>toilet</td>\n",
       "      <td>0.001631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>computer</td>\n",
       "      <td>0.001579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>clock</td>\n",
       "      <td>0.001571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bee</td>\n",
       "      <td>0.001564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>fish</td>\n",
       "      <td>0.001557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bicycle</td>\n",
       "      <td>0.001557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>backpack</td>\n",
       "      <td>0.001475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>rain</td>\n",
       "      <td>0.001475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>apple</td>\n",
       "      <td>0.001341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>sailboat</td>\n",
       "      <td>0.001320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>crab</td>\n",
       "      <td>0.001233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ambulance</td>\n",
       "      <td>0.001109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alarm_clock</td>\n",
       "      <td>0.000851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>house</td>\n",
       "      <td>0.000711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>car</td>\n",
       "      <td>0.000671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cake</td>\n",
       "      <td>0.000615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>crown</td>\n",
       "      <td>0.000601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>camera</td>\n",
       "      <td>0.000528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>radio</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>smiley_face</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>castle</td>\n",
       "      <td>0.000165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             classes  probabilities\n",
       "88            zigzag       0.168252\n",
       "58         lightning       0.133673\n",
       "81          squiggle       0.101783\n",
       "70           rainbow       0.044992\n",
       "53            hammer       0.041519\n",
       "71             rifle       0.035278\n",
       "65            pliers       0.029695\n",
       "49        flip_flops       0.029138\n",
       "0   aircraft_carrier       0.022976\n",
       "41         crocodile       0.020514\n",
       "1           airplane       0.017754\n",
       "61            pencil       0.014396\n",
       "11           bandage       0.014020\n",
       "26             brain       0.013617\n",
       "25         boomerang       0.013593\n",
       "54        helicopter       0.013583\n",
       "31            carrot       0.012211\n",
       "73               saw       0.010504\n",
       "8                arm       0.009910\n",
       "44           dolphin       0.009853\n",
       "51            guitar       0.009802\n",
       "52         hamburger       0.009717\n",
       "86              tree       0.009479\n",
       "22        binoculars       0.009270\n",
       "23              bird       0.008525\n",
       "67            rabbit       0.008420\n",
       "12          baseball       0.008132\n",
       "83             sword       0.008027\n",
       "19              belt       0.007731\n",
       "20             bench       0.007535\n",
       "..               ...            ...\n",
       "57        light_bulb       0.002304\n",
       "87          triangle       0.002302\n",
       "15           bathtub       0.002114\n",
       "14        basketball       0.001986\n",
       "59          mountain       0.001929\n",
       "33               cat       0.001878\n",
       "77             skull       0.001703\n",
       "76             sheep       0.001700\n",
       "39               cow       0.001669\n",
       "84            toilet       0.001631\n",
       "37          computer       0.001579\n",
       "35             clock       0.001571\n",
       "18               bee       0.001564\n",
       "48              fish       0.001557\n",
       "21           bicycle       0.001557\n",
       "9           backpack       0.001475\n",
       "69              rain       0.001475\n",
       "7              apple       0.001341\n",
       "72          sailboat       0.001320\n",
       "40              crab       0.001233\n",
       "3          ambulance       0.001109\n",
       "2        alarm_clock       0.000851\n",
       "56             house       0.000711\n",
       "30               car       0.000671\n",
       "28              cake       0.000615\n",
       "42             crown       0.000601\n",
       "29            camera       0.000528\n",
       "68             radio       0.000242\n",
       "78       smiley_face       0.000225\n",
       "32            castle       0.000165\n",
       "\n",
       "[89 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "class_idx = train_generator.class_indices\n",
    "class_idx_df = pd.DataFrame({'classes':list(class_idx.keys())}).reset_index()\n",
    "sorted_probs = pd.DataFrame({'probabilities':pred.ravel()}).sort_values(by = 'probabilities', ascending=False).\\\n",
    "                            reset_index()\n",
    "\n",
    "merged = pd.merge(class_idx_df, sorted_probs).sort_values('probabilities', ascending=False).drop('index', axis=1)\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T10:23:44.507216Z",
     "start_time": "2018-07-26T10:23:44.504907Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T10:28:56.950129Z",
     "start_time": "2018-07-26T10:28:56.792180Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "not_used = os.listdir('not_used_categories/')\n",
    "not_used = [s.replace('.npy', '') for s in not_used]\n",
    "not_used = [s.replace(' ', '_') for s in not_used]\n",
    "\n",
    "\n",
    "for item in not_used:\n",
    "    if os.path.exists('train/' + item):\n",
    "        os.rmdir('train/' + item)\n",
    "    if os.path.exists('test/'+ item):\n",
    "        os.rmdir('test/' + item)\n",
    "    if os.path.exists('validation/' + item):    \n",
    "        os.rmdir('validation/' + item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
