{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T18:00:57.703746Z",
     "start_time": "2018-08-01T18:00:56.019615Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenny/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from sgdr import SGDRScheduler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T18:04:16.176399Z",
     "start_time": "2018-08-01T18:00:58.310038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6880000 images belonging to 86 classes.\n",
      "Found 430000 images belonging to 86 classes.\n",
      "Data batch shape:  (20, 28, 28, 1)\n",
      "Labels batch shape:  (20, 86)\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_dir = \"./train\"\n",
    "validation_dir = \"./validation\"\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, \n",
    "    target_size = (28,28),\n",
    "    batch_size=20,\n",
    "    class_mode= 'categorical',\n",
    "    color_mode = 'grayscale')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size = (28,28),\n",
    "    batch_size=20,\n",
    "    class_mode = 'categorical',\n",
    "    color_mode = 'grayscale')\n",
    "\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('Data batch shape: ', data_batch.shape)\n",
    "    print('Labels batch shape: ', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T01:20:03.507729Z",
     "start_time": "2018-07-26T01:20:03.502964Z"
    }
   },
   "outputs": [],
   "source": [
    "# callbacks\n",
    "epochs = 10000\n",
    "batch_size = 64\n",
    "epoch_size = 15000\n",
    "\n",
    "schedule = SGDRScheduler(min_lr=1e-5,\n",
    "                         max_lr=1e-3,\n",
    "                         steps_per_epoch=np.ceil(epoch_size/batch_size),\n",
    "                         lr_decay=0.9,\n",
    "                         cycle_length=10,\n",
    "                         mult_factor=1.5)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./graph', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "filepath=\"models/checkpoints/best_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-25T23:59:55.858387Z",
     "start_time": "2018-07-25T23:59:55.744363Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clearing old graphs...\n"
     ]
    }
   ],
   "source": [
    "# construct model\n",
    "\n",
    "print('\\nClearing old graphs...')\n",
    "graph = os.listdir('graph')\n",
    "for file in graph:\n",
    "  os.remove('graph/{}'.format(file))\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (2,2), activation = 'relu', input_shape = (28, 28, 1)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(64, (2,2), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(128, (2,2), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(89, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T00:02:05.529466Z",
     "start_time": "2018-07-25T23:59:58.550386Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3766"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.4863 - acc: 0.0185 - val_loss: 4.4560 - val_acc: 0.0270\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.61800\n",
      "Epoch 2/10000\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 4.3150 - acc: 0.0415 - val_loss: 4.1001 - val_acc: 0.0580\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.61800\n",
      "Epoch 3/10000\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 3.8806 - acc: 0.0955 - val_loss: 3.6984 - val_acc: 0.1220\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.61800\n",
      "Epoch 4/10000\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 3.6510 - acc: 0.1410 - val_loss: 3.4565 - val_acc: 0.1950\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.61800\n",
      "Epoch 5/10000\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 3.4711 - acc: 0.1645 - val_loss: 3.2867 - val_acc: 0.2160\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.61800\n",
      "Epoch 6/10000\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 3.3154 - acc: 0.1910 - val_loss: 3.1337 - val_acc: 0.2430\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.61800\n",
      "Epoch 7/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 3.2151 - acc: 0.2175 - val_loss: 3.0193 - val_acc: 0.2870\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.61800\n",
      "Epoch 8/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 3.1151 - acc: 0.2360 - val_loss: 2.9474 - val_acc: 0.2960\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.61800\n",
      "Epoch 9/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 3.0240 - acc: 0.2480 - val_loss: 2.8217 - val_acc: 0.3280\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.61800\n",
      "Epoch 10/10000\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 2.9539 - acc: 0.2845 - val_loss: 2.6846 - val_acc: 0.3480\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.61800\n",
      "Epoch 11/10000\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 2.8773 - acc: 0.2940 - val_loss: 2.5887 - val_acc: 0.3760\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.61800\n",
      "Epoch 12/10000\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 2.8801 - acc: 0.2745 - val_loss: 2.5740 - val_acc: 0.3710\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.61800\n",
      "Epoch 13/10000\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 2.7702 - acc: 0.3110 - val_loss: 2.4892 - val_acc: 0.3830\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.61800\n",
      "Epoch 14/10000\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 2.6288 - acc: 0.3385 - val_loss: 2.4254 - val_acc: 0.4110\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.61800\n",
      "Epoch 15/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 2.6270 - acc: 0.3480 - val_loss: 2.4507 - val_acc: 0.3960\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.61800\n",
      "Epoch 16/10000\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 2.6404 - acc: 0.3480 - val_loss: 2.4286 - val_acc: 0.4090\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.61800\n",
      "Epoch 17/10000\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 2.5727 - acc: 0.3590 - val_loss: 2.3223 - val_acc: 0.4410\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.61800\n",
      "Epoch 18/10000\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 2.4691 - acc: 0.3650 - val_loss: 2.2701 - val_acc: 0.4500\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.61800\n",
      "Epoch 19/10000\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 2.4853 - acc: 0.3750 - val_loss: 2.2422 - val_acc: 0.4570\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.61800\n",
      "Epoch 20/10000\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 2.4718 - acc: 0.3680 - val_loss: 2.2015 - val_acc: 0.4550\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.61800\n",
      "Epoch 21/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 2.4070 - acc: 0.4070 - val_loss: 2.1566 - val_acc: 0.4640\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.61800\n",
      "Epoch 22/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 2.4543 - acc: 0.3865 - val_loss: 2.1696 - val_acc: 0.4660\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.61800\n",
      "Epoch 23/10000\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 2.3929 - acc: 0.3900 - val_loss: 2.1405 - val_acc: 0.4600\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.61800\n",
      "Epoch 24/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 2.3539 - acc: 0.3915 - val_loss: 2.1106 - val_acc: 0.4660\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.61800\n",
      "Epoch 25/10000\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 2.3355 - acc: 0.4080 - val_loss: 2.1025 - val_acc: 0.4740\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.61800\n",
      "Epoch 26/10000\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 2.2943 - acc: 0.4255 - val_loss: 2.0669 - val_acc: 0.4860\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.61800\n",
      "Epoch 27/10000\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 2.3611 - acc: 0.4140 - val_loss: 2.0505 - val_acc: 0.4920\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.61800\n",
      "Epoch 28/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.1931 - acc: 0.4345 - val_loss: 2.0056 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.61800\n",
      "Epoch 29/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.2980 - acc: 0.4350 - val_loss: 2.0123 - val_acc: 0.4850\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.61800\n",
      "Epoch 30/10000\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 2.2788 - acc: 0.4270 - val_loss: 1.9745 - val_acc: 0.5010\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.61800\n",
      "Epoch 31/10000\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 2.2965 - acc: 0.4340 - val_loss: 1.9804 - val_acc: 0.5050\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.61800\n",
      "Epoch 32/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.1914 - acc: 0.4325 - val_loss: 1.9248 - val_acc: 0.5080\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.61800\n",
      "Epoch 33/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 2.1554 - acc: 0.4470 - val_loss: 1.9202 - val_acc: 0.5260\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.61800\n",
      "Epoch 34/10000\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 2.0757 - acc: 0.4485 - val_loss: 1.9766 - val_acc: 0.4990\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.61800\n",
      "Epoch 35/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.1277 - acc: 0.4575 - val_loss: 1.9176 - val_acc: 0.5070\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.61800\n",
      "Epoch 36/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.1824 - acc: 0.4545 - val_loss: 1.8884 - val_acc: 0.5190\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.61800\n",
      "Epoch 37/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.1508 - acc: 0.4430 - val_loss: 1.8907 - val_acc: 0.5160\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.61800\n",
      "Epoch 38/10000\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 2.1244 - acc: 0.4740 - val_loss: 1.8421 - val_acc: 0.5360\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.61800\n",
      "Epoch 39/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.1197 - acc: 0.4705 - val_loss: 1.8329 - val_acc: 0.5490\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.61800\n",
      "Epoch 40/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.1466 - acc: 0.4645 - val_loss: 1.8767 - val_acc: 0.5220\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.61800\n",
      "Epoch 41/10000\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 2.0304 - acc: 0.4840 - val_loss: 1.8290 - val_acc: 0.5410\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.61800\n",
      "Epoch 42/10000\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 2.1543 - acc: 0.4610 - val_loss: 1.8017 - val_acc: 0.5480\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.61800\n",
      "Epoch 43/10000\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 2.0850 - acc: 0.4670 - val_loss: 1.8302 - val_acc: 0.5310\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.61800\n",
      "Epoch 44/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.1516 - acc: 0.4750 - val_loss: 1.8199 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00044: val_acc did not improve from 0.61800\n",
      "Epoch 45/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.0760 - acc: 0.4805 - val_loss: 1.7825 - val_acc: 0.5510\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.61800\n",
      "Epoch 46/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.1003 - acc: 0.4795 - val_loss: 1.7726 - val_acc: 0.5550\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.61800\n",
      "Epoch 47/10000\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 2.0971 - acc: 0.4675 - val_loss: 1.7436 - val_acc: 0.5640\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.61800\n",
      "Epoch 48/10000\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 2.0107 - acc: 0.4935 - val_loss: 1.7224 - val_acc: 0.5610\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.61800\n",
      "Epoch 49/10000\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 2.0351 - acc: 0.4740 - val_loss: 1.7263 - val_acc: 0.5480\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.61800\n",
      "Epoch 50/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 1.9669 - acc: 0.4985 - val_loss: 1.7298 - val_acc: 0.5590\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.61800\n",
      "Epoch 51/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 2.0035 - acc: 0.4905 - val_loss: 1.7353 - val_acc: 0.5620\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.61800\n",
      "Epoch 52/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.9561 - acc: 0.5015 - val_loss: 1.6981 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.61800\n",
      "Epoch 53/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.9903 - acc: 0.4990 - val_loss: 1.7097 - val_acc: 0.5530\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.61800\n",
      "Epoch 54/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 1.9524 - acc: 0.4970 - val_loss: 1.6934 - val_acc: 0.5670\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.61800\n",
      "Epoch 55/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.0073 - acc: 0.4880 - val_loss: 1.6718 - val_acc: 0.5750\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.61800\n",
      "Epoch 56/10000\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 1.9142 - acc: 0.5120 - val_loss: 1.6486 - val_acc: 0.5810\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.61800\n",
      "Epoch 57/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 1.9031 - acc: 0.5105 - val_loss: 1.6621 - val_acc: 0.5720\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.61800\n",
      "Epoch 58/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.9283 - acc: 0.5080 - val_loss: 1.6382 - val_acc: 0.5810\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.61800\n",
      "Epoch 59/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.9565 - acc: 0.5005 - val_loss: 1.6651 - val_acc: 0.5680\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.61800\n",
      "Epoch 60/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.9123 - acc: 0.5120 - val_loss: 1.6357 - val_acc: 0.5830\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.61800\n",
      "Epoch 61/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.9972 - acc: 0.4960 - val_loss: 1.6737 - val_acc: 0.5760\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.61800\n",
      "Epoch 62/10000\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 1.9845 - acc: 0.4900 - val_loss: 1.6325 - val_acc: 0.5890\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.61800\n",
      "Epoch 63/10000\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 1.8848 - acc: 0.5240 - val_loss: 1.6367 - val_acc: 0.5840\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.61800\n",
      "Epoch 64/10000\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 1.9588 - acc: 0.4985 - val_loss: 1.5965 - val_acc: 0.6020\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.61800\n",
      "Epoch 65/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.8787 - acc: 0.5380 - val_loss: 1.6396 - val_acc: 0.5980\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.61800\n",
      "Epoch 66/10000\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 1.9039 - acc: 0.5195 - val_loss: 1.6039 - val_acc: 0.5830\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.61800\n",
      "Epoch 67/10000\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 1.8341 - acc: 0.5185 - val_loss: 1.6359 - val_acc: 0.5830\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.61800\n",
      "Epoch 68/10000\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 1.8438 - acc: 0.5270 - val_loss: 1.6186 - val_acc: 0.5940\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.61800\n",
      "Epoch 69/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.8758 - acc: 0.5160 - val_loss: 1.5740 - val_acc: 0.6020\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.61800\n",
      "Epoch 70/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.8622 - acc: 0.5260 - val_loss: 1.5662 - val_acc: 0.5850\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.61800\n",
      "Epoch 71/10000\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 1.8688 - acc: 0.5090 - val_loss: 1.5771 - val_acc: 0.5820\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.61800\n",
      "Epoch 72/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.8564 - acc: 0.5180 - val_loss: 1.6019 - val_acc: 0.5990\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.61800\n",
      "Epoch 73/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.8691 - acc: 0.5340 - val_loss: 1.5884 - val_acc: 0.6010\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.61800\n",
      "Epoch 74/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.8437 - acc: 0.5325 - val_loss: 1.5602 - val_acc: 0.6040\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.61800\n",
      "Epoch 75/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.8484 - acc: 0.5320 - val_loss: 1.5629 - val_acc: 0.6060\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.61800\n",
      "Epoch 76/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.8647 - acc: 0.5300 - val_loss: 1.5409 - val_acc: 0.6120\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.61800\n",
      "Epoch 77/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.7821 - acc: 0.5435 - val_loss: 1.5362 - val_acc: 0.5930\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.61800\n",
      "Epoch 78/10000\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.8255 - acc: 0.5400 - val_loss: 1.5707 - val_acc: 0.6090\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.61800\n",
      "Epoch 79/10000\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 1.8366 - acc: 0.5305 - val_loss: 1.5163 - val_acc: 0.6130\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.61800\n",
      "Epoch 80/10000\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 1.8191 - acc: 0.5360 - val_loss: 1.5463 - val_acc: 0.6130\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.61800\n",
      "Epoch 81/10000\n",
      " 70/100 [====================>.........] - ETA: 0s - loss: 1.8310 - acc: 0.5400"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-185be0c8aa0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     callbacks = [schedule, tensorboard, checkpoint])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"models/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "hist = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 100,\n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps=50,\n",
    "    callbacks = [schedule, tensorboard, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T04:02:02.265248Z",
     "start_time": "2018-08-01T04:01:54.458510Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenny/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "json_file = open('models/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights('models/checkpoints/best_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:19:34.718974Z",
     "start_time": "2018-07-27T01:19:34.712901Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T04:13:01.094440Z",
     "start_time": "2018-08-01T04:13:00.946228Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenny/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2c380459b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import imageio\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "test_pred = imageio.imread('test_preds/sketch_output.png', pilmode = 'L')\n",
    "test_pred = np.invert(test_pred)\n",
    "test_pred = imresize(test_pred, (28,28) )\n",
    "\n",
    "# test_pred = imageio.imread('test_predictions/lightning0.png')\n",
    "\n",
    "plt.imshow(test_pred/255, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T04:13:05.549934Z",
     "start_time": "2018-08-01T04:13:05.545707Z"
    }
   },
   "outputs": [],
   "source": [
    "test_pred_reshaped = test_pred.reshape(1, 28, 28, 1)/255\n",
    "pred = loaded_model.predict(test_pred_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T04:13:06.909247Z",
     "start_time": "2018-08-01T04:13:06.893867Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classes</th>\n",
       "      <th>probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cookie</td>\n",
       "      <td>0.136685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>smiley_face</td>\n",
       "      <td>0.111966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ant</td>\n",
       "      <td>0.109577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bench</td>\n",
       "      <td>0.049261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>moon</td>\n",
       "      <td>0.047196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>hamburger</td>\n",
       "      <td>0.037304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>lightning</td>\n",
       "      <td>0.035718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angel</td>\n",
       "      <td>0.026064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bird</td>\n",
       "      <td>0.023059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>radio</td>\n",
       "      <td>0.022118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>snowman</td>\n",
       "      <td>0.020494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>eye</td>\n",
       "      <td>0.019807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>helicopter</td>\n",
       "      <td>0.016516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>spider</td>\n",
       "      <td>0.015845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>hat</td>\n",
       "      <td>0.015523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>donut</td>\n",
       "      <td>0.013355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>brain</td>\n",
       "      <td>0.012070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>belt</td>\n",
       "      <td>0.011248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>binoculars</td>\n",
       "      <td>0.010424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>boomerang</td>\n",
       "      <td>0.009604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>clock</td>\n",
       "      <td>0.009014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>baseball</td>\n",
       "      <td>0.008973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>crocodile</td>\n",
       "      <td>0.008929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bee</td>\n",
       "      <td>0.008784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>crab</td>\n",
       "      <td>0.008713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airplane</td>\n",
       "      <td>0.008503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>light_bulb</td>\n",
       "      <td>0.008409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>cloud</td>\n",
       "      <td>0.008324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>fish</td>\n",
       "      <td>0.008090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>basketball</td>\n",
       "      <td>0.007977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>dog</td>\n",
       "      <td>0.004330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>horse</td>\n",
       "      <td>0.004087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>banana</td>\n",
       "      <td>0.004015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>dolphin</td>\n",
       "      <td>0.003706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>sea_turtle</td>\n",
       "      <td>0.003316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>car</td>\n",
       "      <td>0.003197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>house</td>\n",
       "      <td>0.002940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>pencil</td>\n",
       "      <td>0.002701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>mountain</td>\n",
       "      <td>0.002503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>octopus</td>\n",
       "      <td>0.002408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>rabbit</td>\n",
       "      <td>0.002405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>palm_tree</td>\n",
       "      <td>0.002372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>sailboat</td>\n",
       "      <td>0.002365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>carrot</td>\n",
       "      <td>0.002354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>t-shirt</td>\n",
       "      <td>0.002299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>hand</td>\n",
       "      <td>0.002053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>camera</td>\n",
       "      <td>0.001956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.001948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>penguin</td>\n",
       "      <td>0.001920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>sword</td>\n",
       "      <td>0.001871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>backpack</td>\n",
       "      <td>0.001833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>guitar</td>\n",
       "      <td>0.001756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>hammer</td>\n",
       "      <td>0.001736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arm</td>\n",
       "      <td>0.001682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>butterfly</td>\n",
       "      <td>0.001639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>flower</td>\n",
       "      <td>0.001578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>book</td>\n",
       "      <td>0.001535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>sheep</td>\n",
       "      <td>0.001492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>elephant</td>\n",
       "      <td>0.001264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>castle</td>\n",
       "      <td>0.000584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        classes  probabilities\n",
       "31       cookie       0.136685\n",
       "70  smiley_face       0.111966\n",
       "2           ant       0.109577\n",
       "14        bench       0.049261\n",
       "54         moon       0.047196\n",
       "44    hamburger       0.037304\n",
       "53    lightning       0.035718\n",
       "1         angel       0.026064\n",
       "17         bird       0.023059\n",
       "62        radio       0.022118\n",
       "71      snowman       0.020494\n",
       "40          eye       0.019807\n",
       "48   helicopter       0.016516\n",
       "72       spider       0.015845\n",
       "47          hat       0.015523\n",
       "38        donut       0.013355\n",
       "20        brain       0.012070\n",
       "13         belt       0.011248\n",
       "16   binoculars       0.010424\n",
       "19    boomerang       0.009604\n",
       "28        clock       0.009014\n",
       "7      baseball       0.008973\n",
       "34    crocodile       0.008929\n",
       "12          bee       0.008784\n",
       "33         crab       0.008713\n",
       "0      airplane       0.008503\n",
       "52   light_bulb       0.008409\n",
       "29        cloud       0.008324\n",
       "41         fish       0.008090\n",
       "9    basketball       0.007977\n",
       "..          ...            ...\n",
       "36          dog       0.004330\n",
       "49        horse       0.004087\n",
       "6        banana       0.004015\n",
       "37      dolphin       0.003706\n",
       "66   sea_turtle       0.003316\n",
       "24          car       0.003197\n",
       "50        house       0.002940\n",
       "58       pencil       0.002701\n",
       "55     mountain       0.002503\n",
       "56      octopus       0.002408\n",
       "61       rabbit       0.002405\n",
       "57    palm_tree       0.002372\n",
       "64     sailboat       0.002365\n",
       "25       carrot       0.002354\n",
       "75      t-shirt       0.002299\n",
       "46         hand       0.002053\n",
       "23       camera       0.001956\n",
       "76         tree       0.001948\n",
       "59      penguin       0.001920\n",
       "74        sword       0.001871\n",
       "5      backpack       0.001833\n",
       "43       guitar       0.001756\n",
       "45       hammer       0.001736\n",
       "4           arm       0.001682\n",
       "22    butterfly       0.001639\n",
       "42       flower       0.001578\n",
       "18         book       0.001535\n",
       "68        sheep       0.001492\n",
       "39     elephant       0.001264\n",
       "26       castle       0.000584\n",
       "\n",
       "[77 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# class_idx = train_generator.class_indices\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "with open(\"class_ids.txt\", 'rb') as fp:\n",
    "    class_idx = pickle.load(fp)\n",
    "# categories = os.listdir('full')\n",
    "# categories = [s.replace('.npy', '') for s in categories]\n",
    "\n",
    "class_idx_df = pd.DataFrame({'classes':list(class_idx.keys())}).reset_index()\n",
    "sorted_probs = pd.DataFrame({'probabilities':pred.ravel()}).sort_values(by = 'probabilities', ascending=False).\\\n",
    "                            reset_index()\n",
    "\n",
    "merged = pd.merge(class_idx_df, sorted_probs).sort_values('probabilities', ascending=False).drop('index', axis=1)\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T18:05:23.790614Z",
     "start_time": "2018-08-01T18:05:23.788400Z"
    }
   },
   "outputs": [],
   "source": [
    "# saving class Indexes\n",
    "\n",
    "import pickle\n",
    "\n",
    "class_idx = train_generator.class_indices\n",
    "\n",
    "with open(\"class_ids.txt\", \"wb\") as fp:\n",
    "    pickle.dump(class_idx, fp)\n",
    "\n",
    "with open(\"/home/kenny/Dropbox/flask-practice/class_ids.txt\", \"wb\") as fp:\n",
    "    pickle.dump(class_idx, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T01:28:45.778087Z",
     "start_time": "2018-07-28T01:28:45.566057Z"
    }
   },
   "outputs": [],
   "source": [
    "# removing unused categories\n",
    "\n",
    "\n",
    "import os\n",
    "not_used = os.listdir('not_used_categories/')\n",
    "not_used = [s.replace('.npy', '') for s in not_used]\n",
    "not_used = [s.replace(' ', '_') for s in not_used]\n",
    "\n",
    "\n",
    "for item in not_used:\n",
    "    if os.path.exists('train/' + item):\n",
    "        os.rmdir('train/' + item)\n",
    "    if os.path.exists('test/'+ item):\n",
    "        os.rmdir('test/' + item)\n",
    "    if os.path.exists('validation/' + item):    \n",
    "        os.rmdir('validation/' + item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
